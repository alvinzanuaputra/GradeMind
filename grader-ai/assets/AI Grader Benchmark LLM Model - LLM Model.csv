Model LLM,Developer,Size,"Test Case 1 
(Ground Truth = 95)",,,"Test Case 2
(Ground Truth = 80)",,,"Test Case 3
(Ground Truth = 60)",,,"Test Case 4
(Ground Truth = 90)",,,"Test Case 5
(Ground Truth = 50)",,,"Test Case 6
(Ground Truth = 40)",,,Rata-Rata Error,Rata-Rata Inference TIme (ms),
,,,Skor,Error,Inference Time (s),Skor,Error,Inference Time (s),Skor,Error,Inference Time (s),Skor,Error,Inference Time (s),Skor,Error,Inference Time (s),Skor,Error,Inference Time (s),,,
Llama 3 8B,Meta,"4,7 GB","87,75","7,250","4,785","84,25","4,250","4,283","23,5","36,500","4,379","87,75","2,250","4,199","28,5","21,500","4,199","25,5","14,500","4,179","14,375","4,337",
"Qwen 2,5 7B (Instruct)",Alibaba,"4,7 GB","87,75","7,250","5,08","84,5","4,500","5,672","29,4","30,600","5,511","84,75","5,250","4,899","60,3","10,300","5,92",50,"10,000","5,416","11,317","5,416333333",
Gemma 7B,Google,"5,0 GB","91,25","3,750","15,217","89,5","9,500","15,712","33,3","26,700","16,961",95,"5,000","17,214","52,75","2,750","16,224","68,8","28,800","17,682","12,750","16,50166667",
Mistral 7B (Instruct),Mistral AI,"4,4 GB",96,"1,000","4,613","74,25","5,750","3,955",38,"22,000","4,592","92,5","2,500","4,176","11,7","38,300","3,777",0,"40,000","5,351","18,258","4,411",
"Phi-3 Mini (3,8B)",Microsoft,"2,2 GB","91,85","3,150","3,831","91,5","11,500","4,641","91,875","31,875","3,221","91,5","1,500","3,685","91,875","41,875","4,270","91,875","51,875","5,704","23,629","4,225",
Qwen2.5 3B,Alibaba,"1,9 GB","87,34","7,660","1,922","83,6","3,600","1,658","73,9","13,900","2,507","88,3","1,700","1,585","69,5","19,500","1,649","46,5","6,500","1,887","8,810","1,868",winner
Llama3.2:3b,Meta,"2,0 GB","84,3","10,700","2,098","84,3","4,300","2,038",60,"0,000","2,228","84,3","5,700","2,205",65,"15,000","2,263","65,5","25,500","1,971","10,200","2,133833333",
Gemma 2B,Google,"1,7 GB","91,5","3,500","1,175","91,5","11,500","1,133","91,5","31,500","1,104","91,5","1,500","1,172","91,5","41,500","1,154","91,5","51,500","1,151","23,500","1,148166667",